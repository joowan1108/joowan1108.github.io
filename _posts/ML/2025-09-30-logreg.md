---
layout: single
title: "Logistic Regression"
categories: ML
tag: [머신러닝]
author_profile: false
sidebar:
    nav: "counts"
toc: true
toc_sticky: true
toc_label: Table of Contents
use_math: true
--- 

  
# Classification and Logistic Regression


## Binary Classification

**데이터의 특징과 선형 회귀의 한계**

주어진 입력 데이터 ${x}$에 대해 레이블 y가 **0 또는 1**의 이진 값(binary value)을 가질 때, 이러한 문제를 **이진 분류(Binary Classification)** 라고 부른다.

**선형 회귀(Linear Regression)** 는 연속적인 값을 예측하도록 설계되었기 때문에 이진 분류 문제에 직접 적용하기에는 다음과 같은 문제가 있다.

1. **값의 범위:** 선형 회귀의 예측 값 $h({x}) = \theta^T x$는 −∞부터 +∞까지의 모든 값을 가질 수 있다. 이는 레이블이 ${0, 1}$인 문제 상황에 적합하지 않으며, 예측 결과가 1을 훨씬 초과하거나 0보다 작게 나올 수 있다.

1. **해석의 어려움:** 예측 값이 0.5가 나오더라도 이를 확률로 해석하기 어렵다. 또한, 데이터 분포에 따라 이상치(Outlier)가 발생하면 예측 경계선이 크게 변동될 수 있다.



### Logistic Regression 모델 (Hypothesis Function)

이러한 문제를 해결하기 위해, 가설 함수 $h_\theta({x})$의 출력을 0과 1 사이의 값으로 제한하는 함수를 도입한다. 이 함수가 바로 **시그모이드 함수(Sigmoid Function)** 또는 **로지스틱 함수(Logistic Function)** 이다.

$h_\theta(x)=g(θ^Tx)=\frac {1} {1+e^{−\theta^Tx}}$

여기서 $g(z) = \frac{1} {1 + e^{-z}}$는 시그모이드 함수이다.

**시그모이드 함수의 특징:**

- **출력 범위:** 입력 z(=$\theta^Tx$)가 어떤 값을 가지든, $g(z)$의 출력 값은 항상 **0과 1 사이** (0<g(z)<1)에 놓인다.

- **단조 증가:** 입력 z가 증가하면 출력 $g(z)$도 증가하는 **단조 증가 함수**이다.

### 확률적 해석

모델 $h_\theta(x)$가 주어진 훈련 데이터에 대해 레이블을 가장 잘 예측하도록 파라미터 $\theta$를 찾는 것이 학습 과정의 핵심이다. 이는 곧 데이터의 **Likelihood** 를 **최대화** 하는 $\theta$를 찾는 과정이다. 즉, 데이터의 Likelihood $p(y | x ; \theta)$을 최대화하는 $\theta$을 찾는 과정이다.

문제 상황이 이진 분류이므로 $p(y | x ; \theta)$가 베르누이 확률 분포를 따른다고 하자. 그렇다면 다음을 만족한다.

* $p(y=1 | x, \theta)$ = $h_\theta(x)$
* $p(y=0 | x, \theta)$ = $1 - h_\theta(x)$

따라서 $p(y | x ; \theta)$ = $(h_\theta(x))^y (1 - h_\theta(x))^{1-y}$인 확률분포로 해석된다.

Training examples가 서로 독립적이라는 조건 하에 likelihood 함수 $L(\theta)$는 다음과 같이 쓸 수 있다.

$$L(\theta) = p(y | x ; \theta) = \prod_{i=1}^{n} p(y^{(i)} | x^{(i)} ; \theta) = \prod_{i=1}^{n} (h_\theta(x^{(i)}))^{y^{(i)}} (1-(h_\theta(x^{(i)})))^{1-y^{(i)}}$$

양변에 log을 씌워 곱셈을 덧셈으로 표현하면

$$log L(\theta) = \sum_{i=1}^{n} y^{(i)} log (h(x^{(i)})) + (1-y^{(i)})log(1 - h(x^{(i)}))$$

결국 이 likelihood을 최대화하는 $\theta$를 찾으면 된다. $log L(\theta)$을 $l(\theta)$라고 할 때 Gradient Ascent를 적용해보면 다음과 같다

$$\theta := \theta + \alpha \nabla_{\theta}l(\theta)$$

이 과정을 간단하게 보기 위해서 stochastic하게 보면

$$\frac{\partial l(\theta)}{\partial \theta_j} = (y \frac{1}{g(\theta^T x)} - (1-y)\frac{1}{(1 - g(\theta^T x))}) \cdot \frac{\partial}{\partial \theta_j} g(\theta^T x)$$

Sigmoid 함수 g(x)를 미분하면 sigmoid의 성질에 따라 $(1-g(x)) \cdot g(x)$이므로 대입하면

$$\frac{\partial l(\theta)}{\partial \theta_j} = (y \frac{1}{g(\theta^T x)} - (1-y)\frac{1}{(1 - g(\theta^T x))}) \cdot g(\theta^T x) (1 - g(\theta^T x)) \frac{\partial}{\partial \theta_j} \theta^T x$$

$$= (y(1-g(\theta^Tx)) - (1-y)g(\theta^Tx)) x_j$$

$$= (y - g(\theta^Tx)) x_j$$

결국 $\theta := \theta + \alpha \cdot (y - h_\theta(x)) x_j$, linear regression과 동일하게 update가 된다.

## Multiclass Classification

Label의 개수가 2개보다 많아질 때는 어떤 Machine learning 방법을 써야할까? Binary classification에서는 $p(y | x ; \theta)$가 베르누이 확률 분포를 따른다고 가정했지만 이때는 **다항 분포 (Multinomial distribution)** 를 따른다고 가정한다.  k개의 label이 존재한다고 할 때, 다항 분포를 정의하기 위해서 각 label이 나올 확률을 정의해야 한다. 각 label의 확률을 $\phi_1 .. \phi_k$라고 하자. 그렇다면 multinomal classification 모델은 data를 학습하여 각 data가 속할 수 있는 모든 label의 확률 $\phi_1 .. \phi_k$을 예측하는 것이다.

$$
\theta_1 x_1, ... \theta_k x_k  -> \phi_1, ... \phi_k
$$

하지만 $\theta x$ 의 값은 항상 0~1 범위를 가지지 않고 합 또한 1을 만족하지 않는다. 따라서 Binary classification에 사용한 Sigmoid  함수처럼 output을 확률값으로 변환해줄 함수가 필요하다. Multiclass classification에서는 **Softmax** 함수를 사용한다.

$$
p(y=i | x ; \theta) = \frac {e^{\theta_i^Tx} } {\sum_{j=1}^{k} e^{\theta_j^T x}} = \phi_i
$$

Multiclass classification 모델의 성능을 높이기 위해서 Binary classification처럼 Likelihood $p(y | x ; \theta)$ 을 최대화하는 $\theta$를 구해야 한다. 즉, x가 주어졌을 때 x를 옳은 label 확률값 $\phi$으로 mapping할 확률을 최대화하는 $\theta$를 구해야 하는 것이다.  하나의 example (x,y)에 대해 negative log likelihood를 계산해보면

$$
-log (p(y | x ; \theta)) = - log (\frac{e^{\theta_i^T x}} {\sum_{j=1}^{k} e^{\theta_j x}})
$$

따라서 전체 training set 에 대한 negative log likelihood는

$$
l(\theta) = \sum_{j=1}^{n} - log (\frac{e^{\theta_{y^{(i)}}^T x^{(i)}}} {\sum_{j=1}^{k} e^{\theta_j^T x^{(i)}}})
$$

식을 간단하게 하기 위해 cross entropy loss $l_{ce} : \R^k \times \{1, ... k\} => \R_{\ge 0}$을 도입하여

$$
l_{ce}((\theta_1^Tx, ... \theta_k^Tx), y) = -log (\frac {e^{\theta_y^Tx} } {\sum_{j=1}^{k} e^{\theta_j^T x}})
$$

negative log likelihood을 재작성하면

$$
l(\theta) = \sum_{j=1}^{n}l_{ce}((\theta_1^Tx^{(i)}, ... \theta_k^Tx^{(i)}), y^{(i)})
$$

심지어 Cross entropy loss의 gradient는 간단하다.  $t_i = \theta_i^Tx$라고 하고 $t = (t_1, t_2, ... t_k)$라고 할 때, cross entropy loss의 $t_i$에 대한 gradient 식에 대입하면

$$
\frac {\partial l_{ce} (t,y)} {\partial t_i} = \frac {\partial} {\partial t_i} [log(\sum_{j=1}^{k} e^{t_j}) - t_y]
$$

$$
= \frac{\frac{\partial} {\partial t_i} (\sum_{j=1}^{k} e^{t_j})} {\sum_{j=1}^{k} e^{t_j}} - 1\{ y = i\}
$$

$$
= \frac {e^{t_i}} {\sum_{j=1}^{k} e^{t_j}} - 1\{ y = i\}
$$

$$
= \phi_i - 1\{ y = i\}
$$

Cross entropy loss를 $\theta_i$에 대해 미분하면

$$
\frac {\partial l_{ce} (t,y)} {\partial \theta_i} = \frac {\partial l_{ce} (t,y)} {\partial t_i} \cdot \frac {\partial t_i} {\partial \theta_i} =  ( \phi_i - 1\{ y = i\}) \cdot x^{(j)}
$$

이를 통해 gradient descent로 likelihood를 최대화할 수 있는 $\theta$를 구할 수 있다.





